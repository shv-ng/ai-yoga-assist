{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ys0zlo7x_oL"
   },
   "source": [
    "install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ssUfAIdAvDK0",
    "outputId": "bb3bb916-3eaf-434e-fe84-275decbd0cdb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"All libraries loaded ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEsZm3d7yOBU"
   },
   "source": [
    "Reading data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "PMFUlpXwyXSj",
    "outputId": "ee6bf78b-a71b-47c5-8a43-aaa7ec7cb3cc"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"poses.csv\")\n",
    "\n",
    "def keep_middle_frames(group):\n",
    "    n = len(group)\n",
    "    start = n // 4\n",
    "    end = n - n // 4\n",
    "    return group.iloc[start:end]\n",
    "\n",
    "df = df.groupby(\"sequence_id\", group_keys=False).apply(keep_middle_frames).reset_index(drop=True)\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in [\"frame_id\", \"sequence_id\", \"label\"]]\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nSamples per pose:\")\n",
    "print(df[\"label\"].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ue5A-SLkyk8r"
   },
   "source": [
    "Visualise the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "IlrHAhI_yst5",
    "outputId": "b593af58-fee9-415f-fd3f-48ccf4a55446"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# --- Chart 1: How many samples per pose ---\n",
    "df[\"label\"].value_counts().plot(kind=\"bar\", ax=axes[0], color=\"steelblue\", edgecolor=\"black\")\n",
    "axes[0].set_title(\"Samples per Pose\")\n",
    "axes[0].set_xlabel(\"Pose\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# --- Chart 2: Landmark value distribution ---\n",
    "axes[1].hist(df[feature_cols].values.flatten(), bins=50, color=\"coral\", edgecolor=\"black\")\n",
    "axes[1].set_title(\"Distribution of All Landmark Values\")\n",
    "axes[1].set_xlabel(\"Value (0 to 1)\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYFLeQcCy1tD"
   },
   "source": [
    "Encode Labels & Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbZeFHt6y6mP",
    "outputId": "a6e78573-05cb-4f61-b275-3c3e62ba581d"
   },
   "outputs": [],
   "source": [
    "# Step 1: Convert text labels → numbers\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"label\"])\n",
    "\n",
    "print(\"Label encoding:\")\n",
    "for i, name in enumerate(le.classes_):\n",
    "    print(f\"  {i} → {name}\")\n",
    "\n",
    "# Step 2: Convert numbers → one-hot vectors\n",
    "y_onehot = to_categorical(y)\n",
    "print(\"\\nExample one-hot (first row):\", y_onehot[0])\n",
    "\n",
    "# Step 3: Get features\n",
    "X = df[feature_cols].values\n",
    "\n",
    "# Step 4: Split into train and test\n",
    "# Get unique sequence IDs and split THOSE\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=df[\"sequence_id\"]))\n",
    "\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y_onehot[train_idx], y_onehot[test_idx]\n",
    "\n",
    "print(f\"\\nTraining samples : {len(X_train)}\")\n",
    "print(f\"Testing samples  : {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZyZ1uahzFTt"
   },
   "source": [
    "Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "JH7qpxShzGQc",
    "outputId": "1cc663d2-c4e5-4154-d341-b44521602635"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation=\"relu\", input_shape=(99,)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(6, activation=\"softmax\")\n",
    "], name=\"PoseClassifier\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csRBjfY0zeuq"
   },
   "source": [
    "Compile & Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VeNj8VA9zhN2",
    "outputId": "77a46476-61bb-4b36-8017-dad3591c6e45"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z759dn1M0ixj"
   },
   "source": [
    "Visualise Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "MJpGGe160kqM",
    "outputId": "c1dd7a94-f09e-48c6-ce74-b8904e7fa4a6"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# --- Chart 1: Accuracy ---\n",
    "axes[0].plot(history.history[\"accuracy\"], label=\"Train Accuracy\", color=\"steelblue\")\n",
    "axes[0].plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\", color=\"coral\")\n",
    "axes[0].set_title(\"Accuracy over Epochs\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# --- Chart 2: Loss ---\n",
    "axes[1].plot(history.history[\"loss\"], label=\"Train Loss\", color=\"steelblue\")\n",
    "axes[1].plot(history.history[\"val_loss\"], label=\"Val Loss\", color=\"coral\")\n",
    "axes[1].set_title(\"Loss over Epochs\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Loss\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGuq6set1EDE"
   },
   "source": [
    " Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "0Tz6ENfe1Ep4",
    "outputId": "99d51924-37b2-4048-b5cb-bbf1fa6b8dc8"
   },
   "outputs": [],
   "source": [
    "# Get predictions on test set\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # highest probability = predicted class\n",
    "y_true = np.argmax(y_test, axis=1)        # actual class\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le.classes_,\n",
    "            yticklabels=le.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJQJeJPW1W95"
   },
   "source": [
    "Print All the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WmCd5Sx1Xel",
    "outputId": "970bbd09-5847-4909-8496-969183f511fc"
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"FINAL MODEL EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Overall accuracy\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nOverall Accuracy : {accuracy*100:.2f}%\")\n",
    "print(f\"Overall Loss     : {loss:.4f}\")\n",
    "\n",
    "# Top-1 and Top-2 accuracy\n",
    "top1 = tf.keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred_probs, k=1).numpy().mean()\n",
    "top2 = tf.keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred_probs, k=2).numpy().mean()\n",
    "print(f\"\\nTop-1 Accuracy   : {top1*100:.2f}%  (is correct pose the #1 prediction?)\")\n",
    "print(f\"Top-2 Accuracy   : {top2*100:.2f}%  (is correct pose in top 2 predictions?)\")\n",
    "\n",
    "# Per-pose breakdown\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PER POSE BREAKDOWN\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3mp1M0b1u42"
   },
   "source": [
    "Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUZM_C1E1vNz",
    "outputId": "ef8d8e94-86e8-46b9-aac0-34e8398c21ef"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"models/pose_classifier.h5\")\n",
    "\n",
    "# Save the label encoder (needed to convert numbers back to pose names later)\n",
    "with open(\"models/label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(\"Model saved    → models/pose_classifier.h5\")\n",
    "print(\"Encoder saved  → models/label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATMmR9Ps2AHx"
   },
   "source": [
    "Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ASlTV_l2AmC",
    "outputId": "3da562a5-b061-422c-a2e2-b42ac271c836"
   },
   "outputs": [],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.6\n",
    "\n",
    "def predict_pose(landmarks):\n",
    "    x = np.array(landmarks).reshape(1, -1)\n",
    "    probs = model.predict(x, verbose=0)[0]\n",
    "\n",
    "    top_idx = np.argmax(probs)\n",
    "    confidence = probs[top_idx]\n",
    "    label = le.inverse_transform([top_idx])[0]\n",
    "\n",
    "    if confidence < CONFIDENCE_THRESHOLD:\n",
    "        return \"Unknown Pose\", confidence\n",
    "    return label, confidence\n",
    "\n",
    "# Simulate a single frame coming from webcam\n",
    "fake_frame = np.random.uniform(0, 1, 99)\n",
    "label, confidence = predict_pose(fake_frame)\n",
    "\n",
    "print(f\"Predicted Pose : {label}\")\n",
    "print(f\"Confidence     : {confidence*100:.2f}%\")\n",
    "\n",
    "# Show all pose probabilities\n",
    "probs = model.predict(fake_frame.reshape(1, -1), verbose=0)[0]\n",
    "print(\"\\nAll probabilities:\")\n",
    "for name, prob in zip(le.classes_, probs):\n",
    "    bar = \"█\" * int(prob * 40)\n",
    "    print(f\"  {name:<15} {prob*100:5.1f}%  {bar}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNoMS6ArRonCI1kPrejG/O6",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
